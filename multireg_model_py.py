# -*- coding: utf-8 -*-
"""multireg_model.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dTct4pCEr8wYX01neKF-Ty-CRaw7cksN
"""

"""
@author Vihaan Mittal

Reference to names of columns (From Kaggle):
"": This is usually the index column, which is often left empty or used to indicate the row number.
crim: Per capita crime rate by town.
zn: Proportion of residential land zoned for lots over 25,000 sq. ft.
indus: Proportion of non-retail business acres per town.
chas: Charles River dummy variable (1 if tract bounds river; 0 otherwise).
nox: Nitric oxides concentration (parts per 10 million).
rm: Average number of rooms per dwelling.
age: Proportion of owner-occupied units built prior to 1940.
dis: Weighted distances to five Boston employment centers.
rad: Index of accessibility to radial highways.
tax: Full-value property tax rate per $10,000.
ptratio: Pupil-teacher ratio by town.
black: 1000(Bk - 0.63)^2 where Bk is the proportion of Black residents by town.
lstat: Percentage of lower status of the population.
medv: Median value of owner-occupied homes in $1000s (this is the target variable).
"""

import pandas as pd
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
import matplotlib.pyplot as plt
import seaborn as sns
from pandas.plotting import scatter_matrix
from pandas import set_option
from pandas import read_csv
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.metrics import mean_squared_error

#Loading Data
data1=pd.read_csv('boston.csv')
column_names=["crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","black","lstat","medv"]
X_column_names=["crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","black","lstat"]
data=data1.drop(data1.columns[0],axis=1)
X1=data.drop(data.columns[13],axis=1)
Y1=data.drop(data.columns[0:13],axis=1)
Y=Y1.values
X=X1.values

#EDA
print(data)

description=data.describe()
print(description)

plt.figure()
corMat = data.corr(method='pearson')
sns.heatmap(corMat, square=True)
plt.title("Correlation Heatmap")
plt.show()

plt.figure()
scatter_matrix(data)
plt.show()

data.hist()
plt.show()

#RFE
NUM_FEATURES = 5
model = LinearRegression()
rfe = RFE(estimator=model, n_features_to_select=NUM_FEATURES)
fit = rfe.fit(X, Y)
print("Num Features:", fit.n_features_)
print("Selected Features:", fit.support_)
print("Feature Ranking:", fit.ranking_)
score = rfe.score(X, Y)
print("Model Score with selected features is:", score)

def stepwise_selection(X, Y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):
    included = list(initial_list)
    while True:
        changed = False
        excluded = list(set(X.columns) - set(included))
        new_pval = pd.Series(index=excluded)
        for new_column in excluded:
            model = sm.OLS(Y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()
            new_pval[new_column] = model.pvalues[new_column]
        best_pval = new_pval.min()
        if best_pval < threshold_in:
            best_feature = new_pval.idxmin()
            included.append(best_feature)
            changed = True
            if verbose:
                print('Add {:30} with p-value {:.6}'.format(best_feature, best_pval))
        model = sm.OLS(Y, sm.add_constant(pd.DataFrame(X[included]))).fit()
        pvalues = model.pvalues.iloc[1:]
        worst_pval = pvalues.max()
        if worst_pval > threshold_out:
            changed = True
            worst_feature = pvalues.idxmax()
            included.remove(worst_feature)
            if verbose:
                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))
        if not changed:
            break
    return included

#Stepwise with regular data

result = stepwise_selection(X1, Y1)
print('Resulting features:')
print(result)

#Normalized Data

#Normalizing Data
print("Normalized Data")
scaler = Normalizer().fit(X1)
normalized_data=scaler.transform(X1)
normalized_df=pd.DataFrame(normalized_data,columns=X_column_names)

#Modeling data
scaler = Normalizer().fit(data)
modeling_normalized_data=scaler.transform(data)
modeling_normalized_df=pd.DataFrame(modeling_normalized_data,columns=column_names)

scaler=Normalizer().fit(Y)
normalized_Y = scaler.transform(Y)

#Printing Data
print(modeling_normalized_df)

#Getting Descriptive Stats
description=modeling_normalized_df.describe()
print(description)

#Printing Histogram
modeling_normalized_df.hist()
plt.show()

#Creating heatmap
plt.figure()
corMat = modeling_normalized_df.corr(method='pearson')
sns.heatmap(corMat, square=True)
plt.title("Correlation Heatmap")
plt.show()

#Creating scatterplot matrix
plt.figure()
scatter_matrix(modeling_normalized_df)
plt.show()

#RFE with Normalized Data
NUM_FEATURES = 1
model = LinearRegression()
rfe = RFE(estimator=model, n_features_to_select=NUM_FEATURES)
fit = rfe.fit(normalized_data, normalized_Y)
print("Num Features:", fit.n_features_)
print("Selected Features:", fit.support_)
print("Feature Ranking:", fit.ranking_)
score = rfe.score(normalized_data, normalized_Y)
print("Model Score with selected features is:", score)

#Stepwise with Normalized Data
result = stepwise_selection(normalized_df, modeling_normalized_df['medv'])
print(result)

#Standardized Data

#Creating standardized data
print("Standardized Data")
scaler=StandardScaler().fit(X1)
standardized_data = scaler.transform(X1)
standardized_df=pd.DataFrame(standardized_data,columns=X_column_names)

scaler=StandardScaler().fit(Y)
standardized_Y = scaler.transform(Y)

#Modeling data
scaler = StandardScaler().fit(data)
modeling_standardized_data=scaler.transform(data)
modeling_standardized_df=pd.DataFrame(modeling_standardized_data,columns=column_names)

#Printing Data
print(modeling_standardized_df)

#Getting Descriptive Stats
description=modeling_standardized_df.describe()
print(description)

mse = mean_squared_error(y_test, y_pred)

#Printing Histogram
modeling_standardized_df.hist()
plt.show()

#Creating heatmap
plt.figure()
corMat = modeling_standardized_df.corr(method='pearson')
sns.heatmap(corMat, square=True)
plt.title("Correlation Heatmap")
plt.show()

#Creating scatterplot matrix
plt.figure()
scatter_matrix(modeling_standardized_df)
plt.show()

#RFE with Standardized Data
NUM_FEATURES = 1
model = LinearRegression()
rfe = RFE(estimator=model, n_features_to_select=NUM_FEATURES)
fit = rfe.fit(standardized_data, Y)
print("Num Features:", fit.n_features_)
print("Selected Features:", fit.support_)
print("Feature Ranking:", fit.ranking_)
score = rfe.score(standardized_data, Y)
print("Model Score with selected features is:", score)

#Stepwise with Standardized Data
result = stepwise_selection(standardized_df, Y)
print(result)

#Additional Testing without 'chas'

print("Testing without 'chas'")
Test_X=X1.drop(columns=['chas'])

NUM_FEATURES = 6
model = LinearRegression()
rfe = RFE(estimator=model, n_features_to_select=NUM_FEATURES)
fit = rfe.fit(Test_X, Y)
print("Num Features:", fit.n_features_)
print("Selected Features:", fit.support_)
print("Feature Ranking:", fit.ranking_)
score = rfe.score(Test_X, Y)
print("Model Score with selected features is:", score)